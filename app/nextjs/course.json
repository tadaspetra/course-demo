{"id":"5","lessons":[{"content":"In this course, we will build a **video call** using Agora.\n\nWe will dive deep into what Agora is and why we chose to use it. The result will be a fully functioning video call using a token server for security.","headline":"Video Call with NextJS","id":"135","image":"https://utfs.io/f/e2f5316a-7a48-4ca1-9f51-3b85a4022314-8ds91w.webp","links":[{"type":"github","url":"https://github.com/hungrimind/nextjs-video-call/tree/main"}],"sectionType":"header","subheadline":"Build a fully functioning group call app with NextJS and Agora"},{"content":"# Chapter One: Introduction to Agora\n\nThis first chapter covers the very basics of Agora and goes through setting up an Agora project.","heading":"1Ô∏è‚É£ Chapter One","id":"41711d60-f823-11ee-af8d-6d86a40389be","sectionType":"md","type":"flutter","value":"print('Big Dog!')"},{"content":"Agora is a real-time engagement platform as a service. Similar to how AWS enables anyone to host their cloud infrastructure, Agora enables developers to add real-time engagement and interactivity features to their web and mobile apps without having to understand the complexities of network infrastructure.","heading":"What is Agora?","id":"136","sectionType":"slide","type":"image","value":"courses/flutter/agora-video/agora.png"},{"content":"The best way to explain Real-Time Engagement is with some examples:\n\n* Live audio streaming (Live Podcasting -> think Twitter spaces, Clubhouse)\n* Live video streaming (think -> YouTube Live, Instagram Live, etc)\n* Voice and Video Calls (think Zoom, FaceTime, or Skype, but in your app)\n* Chat (think 1:1 and group chats like iMessage, WhatsApp, Snap DM)\n* Live Stream Gaming (think Twitch but directly in the game)\n* Real-time Metaverse Worlds (think Roblox or Horizon Worlds)\n\nAnything where the user is interacting with other users directly. Agora has the following SDKS to support these use cases.\n\n* Video/Voice - Real-Time Communications (aka video calls and audio calls)\n* Chat - Real-Time Messaging\n* Signaling - Real-Time Data Sharing","heading":"What is Real-Time Engagement?","id":"137","sectionType":"slide","type":"image","value":"courses/flutter/agora-video/real-time.png"},{"content":"In this course, we will build a real-time video communication app. Agora provides us with several options for this.\n\n### I want a simple low-code solution.\n\nThe simplest way to implement video calls within your app is Agora's UIKit. This provides you with all the pre-built elements to create a full video call with a few lines of code. These come with pre-defined UIs to fit the most common use cases, so if you're looking for a quick way to drop in commonly used live video communication features, the UIKit is a great approach.\n\n### I want full control of the call and UI\n\nUsing the complete Agora SDK, you have complete control over everything related to the video call. You have full control of defining the UI, security layer, user management, events, and everything related to the video call.\n\nFor this course, we will cover the Agora Video SDK so that we can fully understand the technology.","heading":"Video Call Options","id":"138","sectionType":"slide","type":"image","value":"courses/flutter/agora-video/video-options.png"},{"content":"We will start this project from scratch. To create a new NextJS project, run the `npx create-next-app@latest` command within your project folder. \n\nThis project will use the best and most up-to-date technology, so use the default options for everything (including tailwind for styling). \n\nWe will remove mostly everything from the starter template to start from scratch.\n\nMost of the code in the starter template is within the `page.tsx`. Let's move the `<main>` tag into the `layout.tsx`, and we can remove the rest of the JSX.\n\n> Use the phone icon below to check the preview and see what your sexy new website should look like. You should see the starter template (for now).","file":"app/layout.tsx","heading":"Create Your Project","highlight":"","id":"139","previewImage":"https://utfs.io/f/429e7b65-1518-4a39-a3b8-75f59ddfbd3d-u83rry.png","sectionType":"slide","type":"flutter","value":"import type { Metadata } from 'next'\nimport { Inter } from 'next/font/google'\nimport './globals.css'\n\nconst inter = Inter({ subsets: ['latin'] })\n\nexport const metadata: Metadata = {\n  title: 'Create Next App',\n  description: 'Generated by create next app',\n}\n\nexport default function RootLayout({\n  children,\n}: {\n  children: React.ReactNode\n}) {\n  return (\n    <html lang=\"en\">\n      <body className={inter.className}>\n        <main className=\"flex min-h-screen flex-col items-center justify-between\">{children}\n        </main>\n      </body>\n    </html>\n  )\n}\n"},{"content":"We'll also remove everything from the page.tsx, and then add the \"use client\"  tag at the top. \n\nNextjs allows us to keep client and server-side logic in the same project, but everything will be handled mostly client-side for our video call app. For example, the UI updates for dynamically managing the video element that plays the audio/video tracks, along with actions like muting the mic or camera, will need to happen on the client device. \n\nThis gives us a brand new starting point.\n\nBuckle your seat belts, baby; Here we go!","file":"app/page.tsx","heading":"Remove Everything","id":"478e3e40-f2b9-11ee-841d-b92b84f437d3","previewImage":"https://utfs.io/f/d1d7eaa0-0c63-4b5e-b711-c9e05169014b-wk5qm3.png","sectionType":"slide","type":"flutter","value":"\"use client\";\n\nexport default function Home() {\n  return <div>hello</div>;\n}\n\n"},{"content":"To use the Agora platform you'll need a developer account. Don't worry sign up is free and everybody gets a free 10,000 minutes of usage per month.\n\nLog into your Agora developer account and click the `New Project` button. Give your project a name, and under Authentication Mode choose Testing Mode.\n\nWe'll cover and enable the Secure Mode option later in the course.\n\n\n\n\n\n","heading":"Create an Agora Account","id":"140","sectionType":"slide","type":"image","value":"courses/flutter/agora-video/create-project.png"},{"content":"Developers need a valid App ID for apps to connect to the Agora platform. This App ID is the key to unlocking access to Agora's full suite of solutions, including the video communication features we'll use in this course.","heading":"App ID","id":"141","sectionType":"slide","type":"image","value":"courses/flutter/agora-video/app-id.png"},{"content":"The `App ID` isn't meant to be secure. Sharing your `App ID` is a bad idea because others can use your key to access the Agora network. We will later add a security layer called tokens that makes your websites safer.\n\nHowever, this `App ID` will be used throughout the site since it is the main connection to your Agora account. Create a `.env` file and add your App ID in there.\n\nYour variable needs to start with `NEXT_PUBLIC_` to be available to use client side. \n\n> If you are putting this project on GitHub, make sure to add this env file to your `.gitignore`. This won't make your site secure, but publicly sharing your `App ID` is still a bad idea.","file":".env","heading":"Create .env file","id":"142","previewImage":"https://utfs.io/f/d1d7eaa0-0c63-4b5e-b711-c9e05169014b-wk5qm3.png","sectionType":"slide","type":"flutter","value":"NEXT_PUBLIC_AGORA_APP_ID = \"<---Your App ID Here --->\""},{"content":"To use the Agora services, we need to install the Agora SDK. In your terminal run the command `npm install agora-rtc-react` to add the Agora package. You should see this package added to your `package.json` file.","file":"package.json","heading":"Add Agora Package","id":"143","sectionType":"slide","type":"yaml","value":"\"dependencies\": {\n  \"agora-rtc-react\": \"^2.1.0\",\n},"},{"content":"You completed the Introductory section of the Course. We have learned what Agora is, and how to install all the prerequisites.\n\nIn this next section, we will build out the form screen where users can enter what channel they want to join.","heading":"2Ô∏è‚É£ Chapter Two","id":"146","sectionType":"md"},{"content":"When joining a video call using Agora, you are joining a Channel. A channel is like a room in real life. People within the channel can talk to each other, while people outside the channel can't talk to the people in the channel.\n\nEach **Channel** needs to have a unique name. These channel names can be created in any way you want as long as they are unique. For every unique channel name, there is exactly **one channel** for people to join. \n\nWe are building a simple group calling application, and our channel name will be a string. This way you can tell your friends to join room ‚Äútadas‚Äù, and they will type in the letters t-a-d-a-s into a form and join that channel.\n\nSo the first step is to create an input form.","heading":"What is a Video Call?","id":"147","sectionType":"slide","type":"image","value":"courses/flutter/agora-video/room.png"},{"content":"We want to create an input field for users to enter the channel name on the initial page. \n\n> All of the styling here is done using TailwindCSS. It is a css framework that makes writing css more straight forward.\n\nWe add an `<h1>` title at the top, which shows \"Nextjs x Agora\", and set the word Agora to blue.\n\nThe key part is the `<form>`. Within the form, we add a label with \"Channel Name\", an input field of type text and name \"channel\", and a submit button at the bottom.","file":"app/page.tsx","heading":"Create a Form","highlight":"","id":"148","previewImage":"https://utfs.io/f/d9eff45d-a297-4c24-ac9a-5228848dff03-nuwucg.png","sectionType":"slide","type":"flutter","value":"<div className=\"flex flex-col items-center\">\n  <h1 className=\"mb-4 mt-20 text-4xl font-extrabold leading-none tracking-tight text-gray-900\">\n    <span className=\"text-black dark:text-neutral-100\">Nextjs x </span>\n    <span className=\"text-blue-500\">Agora</span>\n  </h1>\n  <form>\n    <div className=\"md:flex md:items-center mt-6\">\n      <div>\n        <label\n          className=\"block text-gray-500 font-bold md:text-right mb-1 md:mb-0 pr-4\"\n          htmlFor=\"inline-full-name\"\n        >\n          Channel Name\n        </label>\n      </div>\n      <div>\n        <input\n          className=\"bg-gray-200 appearance-none border-2 border-gray-200 rounded w-full py-2 px-4 text-gray-700 leading-tight focus:outline-none focus:bg-white focus:border-blue-500\"\n          id=\"inline-full-name\"\n          type=\"text\"\n          name=\"channel\"\n          placeholder=\"Enter channel name\"\n          required\n        />\n      </div>\n    </div>\n    <div className=\"text-center\">\n      <button className=\"inline-flex items-center justify-center px-5 py-3 mt-5 text-base font-medium text-center text-white bg-blue-400 rounded-lg hover:bg-blue-500 focus:ring-4 focus:ring-blue-300 dark:focus:ring-blue-900\">\n        Submit\n      </button>\n    </div>\n  </form>\n</div>"},{"content":"The channels will be organized by URL. This is done so you can easily share the URL where you want others to join, and they can jump right into the channel. \n\nThe URL format will be `/channel/<YOURCHANNELNAME>`.\n\nWe can use the `useRouter` provided by Nextjs to do this. Whenever the form is submitted, we call `preventDefault` to prevent the page from submitting the form and refreshing (the default action).\n\nThen we retrieve the value from the channel input and push it using `router.push`\n","file":"app/page.tsx","heading":"Pass the Channel Name","highlight":"1,4,13-19","id":"149","previewImage":"https://utfs.io/f/d9eff45d-a297-4c24-ac9a-5228848dff03-nuwucg.png","sectionType":"slide","type":"flutter","value":"import { useRouter } from \"next/navigation\";\n\nexport default function Home() {\n  const router = useRouter();\n\n  return (\n    <div className=\"flex flex-col items-center\">\n      <h1 className=\"mb-4 mt-20 text-4xl font-extrabold leading-none tracking-tight text-gray-900\">\n        <span className=\"text-black dark:text-neutral-100\">Nextjs x </span>\n        <span className=\"text-blue-500\">Agora</span>\n      </h1>\n      <form\n        onSubmit={(e) => {\n          e.preventDefault();\n          const target = e.target as typeof e.target & {\n            channel: { value: string };\n          };\n          router.push(`/channel/${target.channel.value}`);\n        }}\n      >\n        {/* ... */}\n      </form>\n    </div>\n  );\n}\n\n"},{"content":"Nextjs does routing based on the file path name. Again, the URL we want to go to ends in `/channel/<YOURCHANNELNAME>`.\n\nThe first part is a static text \"channel\", which can be a folder. Then, we need the channel name to be a dynamic parameter that can be retrieved within the file. To do this, put the variable name you want to retrieve in brackets. In our case, we will create another folder called `[channelName]`.\n\nLastly, within the folder, we can create a `page.tsx`.","file":"lib/main.dart","heading":"Create Channel File","highlight":"7-12,16,25","id":"150","sectionType":"slide","type":"image","value":"https://utfs.io/f/0e433c33-d773-4517-ad6a-5b256b4c6619-q5n3ia.png"},{"content":"Next.js passes a params prop to your page component, which contains the dynamic segments of the URL. \n\nIn our case, params will have a property channelName corresponding to the dynamic segment of the URL.\n\nWe can display the channel name in the top left corner to ensure everything works correctly.","file":"app/channel/[channelName]/page.tsx","heading":"Retrieve Parameter","id":"25cc2b20-f609-11ee-b833-f30638ad3797","previewImage":"https://utfs.io/f/42587d82-8083-4234-9394-80b4871f6973-twa4xn.png","sectionType":"slide","type":"flutter","value":"export default function Page({ params }: { params: { channelName: string } }) {\n  return (\n    <main className=\"flex w-full flex-col\">\n      <p className=\"absolute z-10 mt-2 ml-12 text-2xl font-bold text-neutral-900 dark:text-neutral-100\">\n        {params.channelName!}\n      </p>\n    </main>\n  );\n}"},{"content":"You have completed the Form Screen section of the course. We learned how video calls in Agora are based on channels, and to join a channel with your friends, you need a unique channel name. We created a beautiful form for users to enter a string as their channel name.\n\nIn the next section, we will add the logic for the video call and use the channel name, which was passed in, to start up a video call.","heading":"3Ô∏è‚É£ Chapter Three","id":"152","sectionType":"md"},{"content":"All the prerequisites for a video call are met: we have a channel name and an App ID. Now, we create a new `components` folder within the `app` directory and inside create a `Call.tsx` file. Inside the file, we create the `Call` component, which will show the video call.\n\nFor now, it is an empty component that receives `appId` and `channelName` as parameters.\n\n> If you click the phone icon, you should still see an empty screen with the channel name at the top left. It is not broken. Our app will look like an empty screen while implementing the backend logic.","file":"components/Call.tsx","heading":"Call Screen","highlight":"","id":"153","previewImage":"https://utfs.io/f/42587d82-8083-4234-9394-80b4871f6973-twa4xn.png","sectionType":"slide","type":"flutter","value":"\"use client\";\n\nasync function Call(props: { channelName: string }) {\n  return <div></div>;\n}\n\nexport default Call;\n\n"},{"content":"We must add that `Call` component to our dynamic channel name page. \n\nYou might notice we are importing it weirdly. \n\nWhile writing this code, I learned something new about Nextjs. While \"use client\" does render its components on the client side, not all the imported components are necessarily rendered on the client.   \n\nYou can import dynamic imports with `{ssr: false}` to disable anything server-side on the component completely, including imports.","file":"app/channel/[channelName]/page.tsx","heading":"Add Call Component","highlight":"1-3,11-13","id":"41ff9710-fc1b-11ee-921f-0d43590cd1ee","previewImage":"https://utfs.io/f/42587d82-8083-4234-9394-80b4871f6973-twa4xn.png","sectionType":"slide","type":"flutter","value":"import dynamic from \"next/dynamic\";\n\nconst Call = dynamic(() => import(\"../../../components/Call\"), { ssr: false });\n\nexport default function Page({ params }: { params: { channelName: string } }) {\n  return (\n    <main className=\"flex w-full flex-col\">\n      <p className=\"absolute z-10 mt-2 ml-12 text-2xl font-bold text-neutral-900 dark:text-neutral-100\">\n        {params.channelName}\n      </p>\n      <Call\n        channelName={params.channelName}\n      ></Call>\n    </main>\n  );\n}\n\n"},{"content":"Before getting to the code, what does a video call technically contain?\n* Your own video feed aka **Local Video** (to make sure you look good)\n* Other participant's video feed, aka **Remote Video**\n* Buttons (ex. end call, toggle mic, switch camera)\n\nThat's all you need to have a complete video call. While the concept of a video call is complex, Agora's SDK makes it simple.","file":"call.dart","heading":"Parts of a Video Call","highlight":"","id":"154","sectionType":"slide","type":"image","value":"https://utfs.io/f/849c5804-fe76-4c96-bece-ec094284f876-8ds91w.png"},{"content":"The client is the workhorse of everything Agora-related. It is the connection point between your application and the Agora network.\n\n> The network is called SD-RTN‚Ñ¢ or Software Defined Real-Time Network. This is the core technology behind everything Agora and why latency and quality are so much better than WebRTC.\n\nWe start by creating an Agora `client`. This will be used throughout our file. The `createClient` function takes in a configuration object that has two required fields: \n\n* `mode` - can be either \"rtc\" for regular video calling or \"live\" for having an audience and presenter option.\n* `codec` - encoding method\n\n\nWe will use \"rtc\" since our app is a video calling app.","file":"components/Call.tsx","heading":"The Agora Client","highlight":"","id":"155","previewImage":"https://utfs.io/f/42587d82-8083-4234-9394-80b4871f6973-twa4xn.png","sectionType":"slide","type":"flutter","value":"import AgoraRTC, { AgoraRTCProvider, useRTCClient } from \"agora-rtc-react\";\n\nasync function Call(props: { channelName: string }) {\n  const client = useRTCClient(\n    AgoraRTC.createClient({ mode: \"rtc\", codec: \"vp8\" })\n  );\n\n  return <div></div>;\n}\n"},{"content":"Since this client is the workhorse of everything Agora-related, we need to ensure everything within our video call can access this client. To do this, we create an `AgoraRTCProvider`. \n\nThis `AgoraRTCProvider` will allow all the components below access to this client using the `useRTCClient` hook. \n\n> The Agora SDK uses hooks for many video call functions. Those hooks use the client provided by this `AgoraRTCProvider` behind the scenes. ","file":"components/Call.tsx","heading":"Providing the Client","highlight":"8","id":"c8ca4270-00af-11ef-b8bf-d1abfa953329","previewImage":"https://utfs.io/f/42587d82-8083-4234-9394-80b4871f6973-twa4xn.png","sectionType":"slide","type":"flutter","value":"import AgoraRTC, { AgoraRTCProvider, useRTCClient } from \"agora-rtc-react\";\n\nasync function Call(props: { channelName: string }) {\n  const client = useRTCClient(\n    AgoraRTC.createClient({ mode: \"rtc\", codec: \"vp8\" })\n  );\n\n  return <AgoraRTCProvider client={client}></AgoraRTCProvider>;\n}"},{"content":"Next, we create a `VideoFeed` component to house the complete UI for our video call. \n\nThis is the component where we will join the video call, so we also need the channel name here.\n","file":"components/Call.tsx","heading":"VideoFeed Component","highlight":"8,13-17","id":"c2720a40-00bc-11ef-b8bf-d1abfa953329","previewImage":"https://utfs.io/f/42587d82-8083-4234-9394-80b4871f6973-twa4xn.png","sectionType":"slide","type":"flutter","value":"async function Call(props: { channelName: string }) {\n  const client = useRTCClient(\n    AgoraRTC.createClient({ mode: \"rtc\", codec: \"vp8\" })\n  );\n\n  return (\n    <AgoraRTCProvider client={client}>\n      <VideoFeed channelName={props.channelName}></VideoFeed>\n    </AgoraRTCProvider>\n  );\n}\n\nfunction VideoFeed(props: { channelName: string }) {\n  const { channelName } = props;\n\n  return <div></div>;\n}"},{"content":"You must send your local audio and video in a successful video call. You can create a video track using `useLocalVideoTrack` and an audio track using `useLocalAudioTrack`. Once you create them, you can publish them using the `usePublish` hook. \n\nIt‚Äôs important not to have these tracks taking up memory when you are not using them, so close them before you leave the screen. You can call the `close` function on video and audio tracks. ","file":"components/Call.tsx","heading":"Create Local Video and Audio Tracks","highlight":"3-13","id":"86f82730-00e7-11ef-9153-53967d9bcf83","previewImage":"https://utfs.io/f/42587d82-8083-4234-9394-80b4871f6973-twa4xn.png","sectionType":"slide","type":"flutter","value":"function VideoFeed(props: { channelName: string }) {\n  const { channelName } = props;\n  const { isLoading: isLoadingMic, localMicrophoneTrack } =\n    useLocalMicrophoneTrack();\n  const { isLoading: isLoadingCam, localCameraTrack } = useLocalCameraTrack();\n  usePublish([localMicrophoneTrack, localCameraTrack]);\n\n  useEffect(() => {\n    return () => {\n      localCameraTrack?.close();\n      localMicrophoneTrack?.close();\n    };\n  }, []);\n\n  return <div></div>;\n}"},{"content":"At this point, the local user will be ready to join the call. We join using the `useJoin` hook and passing in the appid and channel along with `token:null`. \n\nThis token is used for security purposes. We will implement token security later in the course. But for now, I just want to see my face on the screen. ","file":"components/Call.tsx","heading":"Joining the Call","highlight":"8-12","id":"790b6fa0-00e8-11ef-9153-53967d9bcf83","previewImage":"https://utfs.io/f/42587d82-8083-4234-9394-80b4871f6973-twa4xn.png","sectionType":"slide","type":"flutter","value":"function VideoFeed(props: { channelName: string }) {\n  const { channelName } = props;\n  const { isLoading: isLoadingMic, localMicrophoneTrack } =\n    useLocalMicrophoneTrack();\n  const { isLoading: isLoadingCam, localCameraTrack } = useLocalCameraTrack();\n  usePublish([localMicrophoneTrack, localCameraTrack]);\n\n  useJoin({\n    appid: process.env.NEXT_PUBLIC_AGORA_APP_ID!,\n    channel: channelName,\n    token: null,\n  });\n\n  useEffect(() => {\n    return () => {\n      localCameraTrack?.close();\n      localMicrophoneTrack?.close();\n    };\n  }, []);\n\n  return <div></div>;\n}"},{"content":"We are not receiving other people‚Äôs audio and video yet, but we have all the requirements met to see ourselves. Our video and audio hook gives us an `isLoading` flag. We can use the microphone and the camera flag to check if our devices are ready. \n\nIf they are not ready, we display `Loading devices‚Ä¶`, and once our audio and video are ready, we can show this using the `LocalVideoTrack` component. Pass in the localCameraTrack, set `play={true}`, and give it full width and height.\n\nNow you can run your development server and see your pretty face.","file":"app/components/Call.tsx","heading":"Video UI","highlight":"4-6,10-14","id":"78f54f90-00e8-11ef-9153-53967d9bcf83","previewImage":"https://utfs.io/f/fe5bfe78-707f-4c6d-9b8b-c229a9a41b60-ltcgl9.png","sectionType":"slide","type":"flutter","value":"function VideoFeed(props: { channelName: string }) {\n  // ...\n\n  if (isLoadingMic || isLoadingCam) {\n    return <div className=\"flex flex-col items-center pt-40\">Loading devices...</div>;\n  }\n\n  return (\n    <div className=\"flex h-screen w-full\">\n      <LocalVideoTrack\n        track={localCameraTrack}\n        play={true}\n        className=\"w-full h-full\"\n      />\n    </div>\n  );\n}"},{"content":"It can be a little lonely to be on a video call by yourself. Adding other people to your call works in a similar way. We need to bring in the remote users‚Äô video and audio. We get their video and audio using the `useRemoteUsers` hook. \n\nThen, map through each video track and pass it into the `RemoteUser` object to show their video.\n\nWe haven't done styling at this point, so the UI should look pretty bad. The important thing is that you receive all the video and audio feeds and send out your own video and audio feed. \n\nThe video call is active. Now, let's make it look good.","file":"app/components/Call.tsx","heading":"Bring in Others","highlight":"4,13-15","id":"78dc9770-00e8-11ef-9153-53967d9bcf83","previewImage":"https://utfs.io/f/5d83cad5-831b-40ae-a721-8556073c8566-m6q5wl.png","sectionType":"slide","type":"flutter","value":"function VideoFeed(props: { channelName: string }) {\n  // ...\n\n  const remoteUsers = useRemoteUsers();\n\n  return (\n    <div className=\"flex h-screen w-full\">\n      <LocalVideoTrack\n        track={localCameraTrack}\n        play={true}\n        className=\"w-full h-full\"\n      />\n      {remoteUsers.map((user) => (\n        <RemoteUser user={user} />\n      ))}\n    </div>\n  );\n}"},{"content":"We create a simple grid layout using the `grid` class from tailwind. Then, the `gap-1` class adds some padding between the videos, and the `flex-1` class allows the videos to expand and fill the space.\n\nWe need to dynamically define the columns within the grid based on the number of remote users.\n\nIf there are 0 remote users, that means it's just your local video, so we want only one column. When a remote user joins, we want there to be two columns so the videos are side by side. When there are more than 4 users, we need 3 columns, and when there are more than 9 users, we need 4 columns.\n\nNow we have a nice grid of all the members of the video call.","file":"app/components/Call.tsx","heading":"Make it Pretty","highlight":"4,8-20,29","id":"7875bf50-00e8-11ef-9153-53967d9bcf83","previewImage":"https://utfs.io/f/97e1ab1c-9b55-4669-971e-dcfb035acbbe-lcvwrh.png","sectionType":"slide","type":"flutter","value":"function VideoFeed(props: { channelName: string }) {\n  // ...\n\n  return (\n    <div className=\"flex h-screen w-full\">\n      <div\n        className={`grid gap-1 flex-1 ${\n          remoteUsers.length > 9\n            ? `grid-cols-4`\n            : remoteUsers.length > 4\n            ? `grid-cols-3`\n            : remoteUsers.length >= 1\n            ? `grid-cols-2`\n            : `grid-cols-1`\n        }`}\n      >\n        <LocalVideoTrack\n          track={localCameraTrack}\n          play={true}\n          className=\"w-full h-full\"\n        />\n        {remoteUsers.map((user) => (\n          <RemoteUser user={user} />\n        ))}\n      </div>\n    </div>\n  );\n}"},{"content":"We need some buttons!!! Specifically, we need a mute and end-call button. \n\nFor this, we create a new `Buttons` component and pass the `localMicrophoneTrack` as a prop. The microphone track has a function to control the mute state.","file":"app/components/Button.tsx","heading":"Buttons!!!","id":"549443b0-017c-11ef-b7e9-230775665143","previewImage":"https://utfs.io/f/fe5bfe78-707f-4c6d-9b8b-c229a9a41b60-ltcgl9.png","sectionType":"slide","type":"flutter","value":"import { IMicrophoneAudioTrack } from \"agora-rtc-react\";\n\nfunction Buttons(props: { track: IMicrophoneAudioTrack | null }) {\n\n  return (\n    <div></div>\n  );\n}\n\nexport default Buttons;\n\n"},{"content":"The button component needs to be displayed above the video calls. We do this by adding the `z-10` class. Then, we want it fixed to the bottom of the screen in the center, with some padding.\n\nWe create another `div` within the main layout div where all the buttons go. Here, we add the class `space-x-4` to give the buttons space between them.\n\nFinally, we can add the end call button, which needs to be an `<a>` tag with `href` of `\"/\"`. This can be styled however you want, but I made it red with white text.","file":"app/components/Button.tsx","heading":"End Call Button","highlight":"","id":"eabacdc0-017f-11ef-b7e9-230775665143","previewImage":"https://utfs.io/f/629bce8f-83f1-4c46-9507-04a34c6b08c6-maz5jv.png","sectionType":"slide","type":"flutter","value":"import { IMicrophoneAudioTrack } from \"agora-rtc-react\";\n\nfunction Buttons(props: { track: IMicrophoneAudioTrack | null }) {\n\n  return (\n    <div className=\"fixed z-10 bottom-0 left-0 right-0 flex justify-center pb-4\">\n      <div className=\"flex space-x-4\">\n        <a\n          className=\"px-5 py-3 text-base font-medium text-center text-white bg-red-400 rounded-lg hover:bg-red-500 w-40\"\n          href=\"/\"\n        >\n          End Call\n        </a>\n      </div>\n    </div>\n  );\n}\n"},{"content":"The mute button is slightly more complicated because we must hold its mute state. Depending on whether the user is currently muted, we should display either \"Mute\" or \"Unmute\". \n\nThis can be done with the `useState` hook, and we can display the appropriate text based on the state.\n\nThen, when the button is clicked, we must update that state and enable or disable the microphone using the microphone track we passed.\n\n","file":"app/components/Button.tsx","heading":"Mute Button","highlight":"2,13-21","id":"8ff53c30-0180-11ef-b7e9-230775665143","previewImage":"https://utfs.io/f/87f1b256-182d-461d-8f39-b256a9689259-n7b6n0.png","sectionType":"slide","type":"flutter","value":"function Buttons(props: { track: IMicrophoneAudioTrack | null }) {\n  const [isMuted, setIsMuted] = useState(false);\n\n  return (\n    <div className=\"fixed z-10 bottom-0 left-0 right-0 flex justify-center pb-4\">\n      <div className=\"flex space-x-4\">\n        <a\n          className=\"px-5 py-3 text-base font-medium text-center text-white bg-red-400 rounded-lg hover:bg-red-500 w-40\"\n          href=\"/\"\n        >\n          End Call\n        </a>\n        <button\n          className=\"px-5 py-3 text-base font-medium text-center text-white bg-gray-400 rounded-lg hover:bg-gray-500 w-40\"\n          onClick={() => {\n            setIsMuted(!isMuted);\n            props.track?.setEnabled(isMuted);\n          }}\n        >\n          {isMuted ? \"Unmute\" : \"Mute\"}\n        </button>\n      </div>\n    </div>\n  );\n}\n"},{"content":"You have completed the Call Screen section of the course. In this section, we built a fully functioning video call! \n\nIn the next section, we will create a token server and use it to add token security to our application, making it production-ready!\n\n","heading":"4Ô∏è‚É£ Chapter Four","id":"173","sectionType":"md"},{"content":"This section is all about adding tokens to our application. Until now, we haven't used tokens at all so why do we need to add them?\n\nBecause of ***Security.***\n\nWithout tokens, as long as someone has our `appId` they can join any room that they want.\n\nBut once tokens are added we can manage and allow the users to only join the room if they have a valid token. It is a form of authentication and user management.","heading":"Why Tokens?","id":"174","sectionType":"slide","type":"image","value":"courses/flutter/agora-video/security.jpg"},{"content":"The first thing we need to do is go into our Agora console and go into the project we are using for this application.\n\nSince we started building this application in test mode, we should see a button to enable Primary Certificate.\n\nThis certificate enables token authentication on our project and provides a string for setting up the token generator.","heading":"Enable Certificate","id":"175","sectionType":"slide","type":"image","value":"courses/flutter/agora-video/enable-certificate.png"},{"content":"We should see another popup after we enable the certificate to \"Disable Unauthorized Access\".\n\nAdding a Primary Certificate doesn't remove the test mode access, so make sure to click this disable button to fully secure our application.","heading":"Disable Test Mode","id":"176","sectionType":"slide","type":"image","value":"courses/flutter/agora-video/disable-access.png"},{"content":"The next step is creating a Token Generator. A Token Generator is a completely separate web server that creates and updates your tokens.\n\nNow, you can build your own backend service to handle all the token management, but the Agora team has built a one-click deployment for the most popular hosting platforms. You must add your `App ID` and the `Certificate ID`.\n\n<a href=\"https://docs.agora.io/en/video-calling/get-started/authentication-workflow?platform=react-js#create-and-run-a-token-server\" target=\"_blank\">Click here to be taken to the token generators.</a>\n\n> I like deploying with Render, but any option works.\n\nYou will see something asking about CORS, which stands for Cross-Origin Resource Sharing. This allows you to request a domain different from the site you are requesting from. In this case, our backend server will be making requests to the Agora network, so make sure to allow it.\n","heading":"Create a Token Generator","id":"177","sectionType":"slide","type":"image","value":"courses/flutter/agora-video/backend-logic.png"},{"content":"The first time I did this, I wondered why we needed the backend and couldn't request the token directly from our video call app.\n\nThis is again for **security reasons**. When requesting the token, we include the App ID. If this was coming directly from the device, this network request could be intercepted, and the malicious actor could gain access to that App ID and potentially that video call.\n\nWhen we request the backend, the App ID and Certificate ID are stored in the server, making it impossible to access from the application layer.","heading":"Why Backend?","id":"178","sectionType":"slide","type":"image","value":"courses/flutter/agora-video/backend-logic.png"},{"content":"This server we created will have a specific URL that can be reached. You should find this in the dashboard where you deployed it.\n\n> Note: If you deployed using Render, it should look something like https://agora-token-server-xxxx.onrender.com.","file":".env","heading":"Add URL to .env","id":"179","sectionType":"slide","type":"flutter","value":"NEXT_PUBLIC_AGORA_APP_ID = \"<--Your App ID-->\"\n\nNEXT_PUBLIC_AGORA_TOKEN_URL = \"<--Your Token URL-->\""},{"content":"To keep our code organized, create another file called `token.ts` within an `app/utils` folder.\n\nHere, we define just one function, `fetchToken`, which calls our web server using the `fetch` request.\n\nThe URL is formatted as:\n\n```\n$tokenUrl/<product>/$channelName/<role>/<token-type>/${uid.toString()}/?expiry=<time-in-seconds>\n```\n\n* **$tokenUrl** - Base URL that we saved in `.env`.\n* **\\<product>** - Type of token. Either `rtc` or `rtm`, which are different Agora products.\n* **$channelName** - Which channel name we are requesting a token for.\n* **\\<role>** - Users role. Either `publisher` or `subscriber`.\n* **\\<token-type>** - Either `uid` for integer or `userAccount` for string. `uid` is recommended.\n* **${uid.toString()}** - UID for the user requesting a token. In this case, we pass 0 because the local user requests it.\n* **expiry=45** - This is optional. The number is in seconds. By default, it is 24 hours, but we are making it 45 seconds to test to ensure new tokens are created properly. You should remove this when your app is in production.\n\n> Note: We chose 45 seconds because the `token-privilege-will-expire` event is triggered 30 seconds before your token expires. We will get to this callback soon.\n\nIf our request is successful with status `200` we will decode the response and return our token.","file":"app/utils/token.ts","heading":"Fetch Token Function","id":"1f3887f0-0198-11ef-b7e9-230775665143","sectionType":"slide","type":"flutter","value":"export async function fetchToken(channelName: string) {\n    try {\n        const response = await fetch(\n            `${process.env.NEXT_PUBLIC_AGORA_TOKEN_URL\n            }/rtc/${channelName}/publisher/uid/${0}/?expiry=45`\n        );\n        const data = (await response.json()) as { rtcToken: string };\n        if (!data.rtcToken) {\n            throw \"RTC token not found\";\n        }\n        console.log(\"RTC token fetched from server: \", data.rtcToken);\n        return data.rtcToken;\n    } catch (error: any) {\n        console.error(error);\n        throw error;\n    }\n}"},{"content":"There are two places where we need to retrieve tokens:\n\n1. When we initially joined the video call.\n2. When our old token is expiring.\n\nWe want access to the token in the `useJoin` function, so we pass an `initialToken` parameter to the `VideoFeed` component. ","file":"app/components/Call.tsx","heading":"Fetch Initial Token","highlight":"10,16,17,28","id":"a700ccc0-01c4-11ef-a90b-6510fc6590ac","sectionType":"slide","type":"flutter","value":"async function Call(props: { channelName: string }) {\n  const client = useRTCClient(\n    AgoraRTC.createClient({ mode: \"rtc\", codec: \"vp8\" })\n  );\n\n  return (\n    <AgoraRTCProvider client={client}>\n      <VideoFeed\n        channelName={props.channelName}\n        initialToken={await fetchToken(props.channelName)}\n      ></VideoFeed>\n    </AgoraRTCProvider>\n  );\n}\n\nfunction VideoFeed(props: { channelName: string; initialToken: string }) {\n  const { channelName, initialToken } = props;\n  const { isLoading: isLoadingMic, localMicrophoneTrack } =\n    useLocalMicrophoneTrack();\n  const { isLoading: isLoadingCam, localCameraTrack } = useLocalCameraTrack();\n  usePublish([localMicrophoneTrack, localCameraTrack]);\n  const remoteUsers = useRemoteUsers();\n  const { audioTracks } = useRemoteAudioTracks(remoteUsers);\n\n  useJoin({\n    appid: process.env.NEXT_PUBLIC_AGORA_APP_ID!,\n    channel: channelName,\n    token: initialToken,\n  });\n}\n\n"},{"content":"The second place we need to fetch the token is when it expires. This is done with the `useClientEvent` hook. This hook gives you access to the events that fire off in the Agora network. \n\nWe must pass the client to this hook, which we can retrieve using the `useRTCClient` hook.\n\nThe specific event we want to handle is `token-privilege-will-expire`, which is triggered 30 seconds before our token expires.\n\nIn this event, we must fetch a new token and pass the token to the `renewToken` function on the client.\n\nWe have our token system fully working! Feel free to remove the 45-second expiration in the token request URL to make it the default 24 hours.","file":"app/components/Call.tsx","heading":"Renew Token","highlight":"8,17-26","id":"af6e1660-01c4-11ef-a90b-6510fc6590ac","sectionType":"slide","type":"flutter","value":"function VideoFeed(props: { channelName: string; initialToken: string }) {\n  const { channelName, initialToken } = props;\n  const { isLoading: isLoadingMic, localMicrophoneTrack } =\n    useLocalMicrophoneTrack();\n  const { isLoading: isLoadingCam, localCameraTrack } = useLocalCameraTrack();\n  const remoteUsers = useRemoteUsers();\n  const { audioTracks } = useRemoteAudioTracks(remoteUsers);\n  const client = useRTCClient();\n\n  usePublish([localMicrophoneTrack, localCameraTrack]);\n  useJoin({\n    appid: process.env.NEXT_PUBLIC_AGORA_APP_ID!,\n    channel: channelName,\n    token: initialToken,\n  });\n\n  useClientEvent(client, \"token-privilege-will-expire\", () => {\n    fetchToken(props.channelName)\n      .then((token) => {\n        console.log(\"RTC token fetched from server: \", token);\n        if (token) return client.renewToken(token);\n      })\n      .catch((error) => {\n        console.error(error);\n      });\n  });\n\n // ...\n}"},{"content":"### Congratulations\n\n**That's it!** You have now created a fully functional video call using Agora. \n\nIf you enjoyed this course, I would really appreciate it if you shared it with your friends or even just told them about [hungrimind.com](https://www.hungrimind.com). But in general, thank you so much, and I hope to see you in the next course.","heading":"üéâ The End","id":"184","sectionType":"md"}]}